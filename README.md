# MACHINE-LEARNING-PROJECTS
Machine learning project using Random Forest to analyze and predict violence against women and girls, providing insights for social impact and policy-making.
# Violence Against Women and Girls Prediction using Random Forest

This project applies data science and machine learning techniques to analyze and predict incidents of violence against women and girls (VAWG). Using a real-world dataset and the Random Forest algorithm, we aim to uncover patterns and assist in early intervention strategies.

## 📌 Objectives

- Analyze and clean VAWG-related data
- Identify patterns in demographics, regions, and types of violence
- Train a Random Forest model for prediction
- Evaluate model accuracy and feature importance
- Provide visual insights to aid NGOs and policymakers

## 🧠 Technologies Used

- Python (Pandas, NumPy, Scikit-learn, Seaborn, Matplotlib)
- Random Forest for prediction
- Label encoding & feature engineering
- Model evaluation using MAE, RMSE, and R²

## 📊 Key Outcomes

- High accuracy in predicting types of violence
- Identification of vulnerable demographics and regions
- Actionable insights for data-backed policy and prevention

## 🌍 Social Impact

This project demonstrates how data science can be applied to real-world humanitarian issues. The goal is to help governments, researchers, and NGOs make informed decisions to reduce violence through early detection and awareness.

## 📁 Dataset

The dataset includes details such as:
- Country/Region
- Age Group
- Year of Incident
- Type of Violence

(Source: Public datasets like Kaggle)

## 🧪 Model Performance

- MAE, RMSE, R² Score evaluated
- Feature importance visualized
- Cross-validation and hyperparameter tuning performed

## 🚀 Future Work

- Real-time prediction API using FastAPI
- Integration with PowerBI dashboards
- Ethical handling of sensitive data and privacy

---

🔗 **References**:
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [Kaggle Datasets](https://www.kaggle.com/datasets)
- [Responsible AI Practices](https://ai.google/responsibilities/responsible-ai-practices/)


